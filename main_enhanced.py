#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– AI ìë™í™” í—ˆë¸Œ - í†µí•© ë²„ì „
Telegram + Google Drive + Gmail + Calendar + Notion + Slack + n8n + Gemini AI

ëª¨ë“  ìë™í™” ëª¨ë“ˆì„ í•˜ë‚˜ì˜ í”„ë¡œê·¸ë¨ìœ¼ë¡œ í†µí•© ì‹¤í–‰
"""

import os
import logging
import tempfile
import shutil
import subprocess
import threading
import time
import json
import re
import math
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from typing import Optional
from zoneinfo import ZoneInfo



import google.generativeai as genai
from modules.logging_setup import setup_logger
from modules.env_check import assert_env
try:
    from modules.drive_watcher import poll_drive_once
except Exception:
    poll_drive_once = None

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, ApplicationBuilder

# Google Drive API imports
try:
    from google.oauth2.service_account import Credentials
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaIoBaseDownload
    import io
except ImportError:
    logger = logging.getLogger(__name__)
    logger.warning("Google Drive libraries not installed. Drive functionality will be disabled.")

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler('automation_hub.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Reduce httpx logging noise
logging.getLogger("httpx").setLevel(logging.WARNING)

# =============================================================================
# ENVIRONMENT VARIABLES
# =============================================================================

# Core settings
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "8288922587:AAHUADrjbeLFSTxS_Hx6jEDEbAW88dOzgNY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyAP8A5YjpwqOkHo0YLhXUMdzFubYoWSwMk")
OWNER_ID = os.getenv("OWNER_ID", "5833561465")

# Google Drive settings
GOOGLE_SERVICE_JSON_PATH = os.getenv("GOOGLE_SERVICE_JSON_PATH", "service_account.json")
DRIVE_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID", "")

# Gmail settings
GMAIL_CLIENT_SECRET_PATH = os.getenv("GMAIL_CLIENT_SECRET_PATH", "gmail_credentials.json")
GMAIL_TOKEN_PATH = os.getenv("GMAIL_TOKEN_PATH", "gmail_token.json")

# Calendar settings
GOOGLE_CALENDAR_ID = os.getenv("GOOGLE_CALENDAR_ID", "primary")

# Notion settings
NOTION_TOKEN = os.getenv("NOTION_TOKEN", "")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID", "")

# Slack settings
SLACK_BOT_TOKEN = os.getenv("SLACK_BOT_TOKEN", "")
SLACK_CHANNEL_ID = os.getenv("SLACK_CHANNEL_ID", "")

# n8n settings
N8N_WEBHOOK_URL = os.getenv("N8N_WEBHOOK_URL", "")
N8N_API_KEY = os.getenv("N8N_API_KEY", "")

# Processed files tracking
PROCESSED_FILES_DB = "processed_files.json"

# =============================================================================
# GEMINI AI SETUP
# =============================================================================

try:
    genai.configure(api_key=GEMINI_API_KEY)
    # Enhanced generation config for stability and performance
    generation_config = {
        "temperature": float(os.getenv("GEN_TEMPERATURE", "0.2")),
        "top_p": 0.9,
        "max_output_tokens": int(os.getenv("GEN_MAX_OUTPUT_TOKENS", "1024")),
    }
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    model = genai.GenerativeModel(
        'gemini-2.5-pro',
        generation_config=generation_config,
        safety_settings=safety_settings
    )
    logger.info("âœ… Gemini AI initialized (gemini-2.5-flash with enhanced config)")
except Exception as e:
    logger.error(f"âŒ Failed to initialize Gemini: {e}")
    model = None

# =============================================================================
# ENHANCED UTILITIES
# =============================================================================



# =============================================================================
# FILE PROCESSING UTILITIES
# =============================================================================

def convert_voice_to_wav(input_path: str, output_path: str) -> bool:
    """Convert voice file (ogg/mp3) to wav format"""
    try:
        if not shutil.which('ffmpeg'):
            logger.error("ffmpeg not found. Please install ffmpeg and ensure it's in PATH.")
            return False
        cmd = ['ffmpeg', '-i', input_path, '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', output_path, '-y']
        subprocess.run(cmd, check=True, capture_output=True)
        return True
    except Exception as e:
        logger.error(f"Error converting voice: {e}")
        return False


def transcribe_audio(wav_path: str) -> str:
    """Transcribe audio to text using Gemini"""
    if not model:
        return "Gemini client not initialized."

    try:
        with open(wav_path, 'rb') as audio_file:
            audio_data = audio_file.read()

        res = generate_vision_safe(
            "Transcribe this audio to text. Provide only the text without explanations.",
            parts=[{"mime_type": "audio/wav", "data": audio_data}]
        )
        response = res.get("text") if res.get("ok") else "ìŒì„± ì „ì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤." 
        return response.strip() if response else "ìŒì„± ì „ì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"Error transcribing: {e}")
        return "ìŒì„± ì „ì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."


def extract_text_from_pdf(pdf_path: str) -> str:
    """Extract text from PDF"""
    try:
        import PyPDF2
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = "".join([page.extract_text() + "\n" for page in reader.pages])
        return text
    except Exception as e:
        logger.error(f"Error extracting PDF: {e}")
        return "PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"


def extract_text_from_docx(docx_path: str) -> str:
    """Extract text from DOCX"""
    try:
        from docx import Document
        doc = Document(docx_path)
        return "\n".join([p.text for p in doc.paragraphs])
    except Exception as e:
        logger.error(f"Error extracting DOCX: {e}")
        return "DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"


def extract_text_from_txt(txt_path: str) -> str:
    """Extract text from TXT"""
    encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin-1']
    for enc in encodings:
        try:
            with open(txt_path, 'r', encoding=enc, errors='replace') as file:
                return file.read()
        except Exception:
            continue
    return "í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨"


def map_reduce_summarize(text: str, max_chunk_size: int = 8000, max_final_summary: int = 1000) -> str:
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ Map-Reduce ë°©ì‹ìœ¼ë¡œ ìš”ì•½
    1. í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    2. ê° ì²­í¬ ìš”ì•½ (Map)
    3. ìš”ì•½ ë‚´ìš© í•©ì³ì„œ ìµœì¢… ìš”ì•½ (Reduce)
    """
    if not model:
        return "Gemini client not initialized."

    try:
        # í…ìŠ¤íŠ¸ê°€ ì§§ìœ¼ë©´ ì¼ë°˜ ìš”ì•½
        if len(text) <= max_chunk_size:
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ë‚´ìš©ë§Œ {max_final_summary}ì ì´ë‚´ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text}

ìš”ì•½:"""
            res = generate_text_safe(prompt, temperature=0.3, max_tokens=max_final_summary)
            return res.get("text", "ìš”ì•½ ì‹¤íŒ¨") if res.get("ok") else "ìš”ì•½ ì‹¤íŒ¨"

        # ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
        chunks = []
        current_pos = 0
        while current_pos < len(text):
            chunk_end = min(current_pos + max_chunk_size, len(text))
            
            # ë¬¸ì¥ ê²½ê³„ ì°¾ê¸°
            if chunk_end < len(text):
                last_period = text.rfind('.', current_pos, chunk_end)
                if last_period > current_pos + max_chunk_size // 2:
                    chunk_end = last_period + 1
            
            chunk = text[current_pos:chunk_end].strip()
            if chunk:
                chunks.append(chunk)
            current_pos = chunk_end

        # ê° ì²­í¬ë³„ ìš”ì•½ (Map)
        chunk_summaries = []
        for i, chunk in enumerate(chunks):
            prompt = f"""ì´ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
{i+1}/{len(chunks)}ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤.

ë‚´ìš©:
{chunk}

ìš”ì•½:"""
            res = generate_text_safe(prompt, temperature=0.3, max_tokens=300)
            if res.get("ok"):
                chunk_summaries.append(res["text"])

        # ìš”ì•½ ë‚´ìš© í•©ì¹˜ê¸° (Reduce)
        if chunk_summaries:
            combined_summaries = "\n\n".join([f"- {s}" for s in chunk_summaries])
            final_prompt = f"""ë‹¤ìŒì€ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¶€ë¶„ë³„ë¡œ ìš”ì•½í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ë¥¼ ì „ì²´ë¥¼ ì•„ìš°ë¥´ëŠ” í•˜ë‚˜ì˜è¿è´¯ëœ ìš”ì•½ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
{max_final_summary}ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ë¶€ë¶„ë³„ ìš”ì•½:
{combined_summaries}

ìµœì¢… ìš”ì•½:"""
            res = generate_text_safe(final_prompt, temperature=0.3, max_tokens=max_final_summary)
            return res.get("text", "ìµœì¢… ìš”ì•½ ì‹¤íŒ¨") if res.get("ok") else "ìµœì¢… ìš”ì•½ ì‹¤íŒ¨"

        return "ìš”ì•½í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        logger.error(f"Map-reduce ìš”ì•½ ì˜¤ë¥˜: {e}")
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# Treat common text-like extensions as plain text previewable types
SUPPORTED_TEXT_EXTS = {
    '.txt', '.md', '.markdown', '.json', '.jsonl', '.yaml', '.yml', '.csv', '.log', '.ini', '.cfg', '.conf',
    '.py', '.js', '.ts', '.jsx', '.tsx', '.css', '.html', '.htm', '.xml', '.java', '.rb', '.go', '.rs', '.sh', '.bat', '.ps1', '.toml', '.sql'
}



# === [AUTO-INJECT] telegram commands ===





# =============================================================================
# TELEGRAM BOT HANDLERS
# =============================================================================

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /start command"""
    welcome_message_raw = (
        "ğŸ¤– **AI ìë™í™” í—ˆë¸Œ** ì‹œì‘í•©ë‹ˆë‹¤! ğŸš€\n\n"
        "âœ… **í™œì„±í™”ëœ ê¸°ëŠ¥:**\n"
        "â€¢ ğŸ“± Telegram ë©”ì‹œì§€ ë¶„ì„ (Geminiê°€ ìë™ìœ¼ë¡œ ì˜ë„ íŒë‹¨)\n"
        "â€¢ ğŸ¤ ìŒì„± ë©”ì‹œì§€ â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ë° ë¶„ì„\n"
        "â€¢ ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ (Gemini Vision)\n"
        "â€¢ ğŸ“„ ë¬¸ì„œ ë¶„ì„ (PDF/DOCX/TXT)\n"
        "â€¢ ğŸ“ Google Drive ìë™ ê°ì‹œ\n"
        "â€¢ ğŸ“§ Gmail ìƒˆ ë©”ì¼ ë¶„ì„\n"
        "â€¢ ğŸ“… Calendar ë¦¬ë§ˆì¸ë”\n"
        "â€¢ ğŸ’¬ Slack ì—°ë™\n"
        "â€¢ ğŸ“ Notion ìë™ ê¸°ë¡\n"
        "â€¢ ğŸ”— n8n ì›Œí¬í”Œë¡œìš° ì—°ë™\n\n"
        "íŒŒì¼ì´ë‚˜ Google Driveì— ì—…ë¡œë“œí•´ë³´ì„¸ìš”!\n"
        "AIê°€ ìë™ìœ¼ë¡œ ë¶„ì„í•´ì„œ ê²°ê³¼ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤."
    )
    formatted_message, parse_mode = format_ai_text(welcome_message_raw)
    await update.message.reply_text(formatted_message, parse_mode=parse_mode)
    logger.info(f"New user started bot: {update.effective_user.id}")








# === [AUTO-INJECT] message routing ===
from modules.gemini_client import generate_text_safe
from modules.telegram_utils import format_ai_text

async def handle_text(update, context):
    chat_id = update.effective_chat.id
    text = (update.message.text or "").strip()

    if not text:
        formatted_message, parse_mode = format_ai_text("ë‚´ìš©ì´ ë¹„ì–´ ìˆì–´ìš”. í…ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.")
        await context.bot.send_message(chat_id, formatted_message, parse_mode=parse_mode)
        return

    # Use Gemini to handle all text inputs, letting it determine the intent
    prompt = f"ì‚¬ìš©ìì˜ ìš”ì²­: {text}\n\nì´ ìš”ì²­ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ê±°ë‚˜, í•„ìš”í•œ ê²½ìš° ë¶„ì„/ìš”ì•½í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”."
    res = generate_text_safe(prompt)
    
    if res.get("ok"):
        formatted_message, parse_mode = format_ai_text(res["text"])
        await context.bot.send_message(chat_id, formatted_message, parse_mode=parse_mode)
    else:
        formatted_message, parse_mode = format_ai_text("ìš”ì²­ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í‘œí˜„ì„ ì¡°ê¸ˆ ë°”ê¿” ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        await context.bot.send_message(chat_id, formatted_message, parse_mode=parse_mode)
# === [/AUTO-INJECT] ===


async def handle_voice_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle voice messages"""
    user_id = update.effective_user.id
    voice = update.message.voice

    logger.info(f"Received voice from user {user_id}")

    try:
        # Download and convert
        file = await context.bot.get_file(voice.file_id)
        with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as ogg_file:
            await file.download_to_drive(ogg_file.name)
            ogg_path = ogg_file.name

        wav_path = ogg_path.replace('.ogg', '.wav')
        if not convert_voice_to_wav(ogg_path, wav_path):
            await update.message.reply_text("âŒ ìŒì„± ë³€í™˜ ì‹¤íŒ¨ (ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”)")
            return

        # Transcribe
        transcription = transcribe_audio(wav_path)
        if transcription == "ìŒì„± ì „ì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.":
            formatted_message, parse_mode = format_ai_text(transcription)
            await update.message.reply_text(formatted_message, parse_mode=parse_mode)
            os.unlink(ogg_path)
            os.unlink(wav_path)
            return

        # Analyze with Gemini
        res = generate_text_safe(f"ìŒì„± ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”. ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\n{transcription}")
        summary = res.get("text") if res.get("ok") else "ìŒì„± ë¶„ì„ ë° ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤." 

        message = (
            "ğŸ¤ ìŒì„± ë¶„ì„ ê²°ê³¼:\n\n"
            f"ì „ì‚¬:\n{transcription}\n\n"
            f"ìš”ì•½:\n{summary}"
        )
        await update.message.reply_text(message)

        # Save to Notion
        if NOTION_TOKEN:
            try:
                from modules.notion_updater import save_transcript_to_notion
                save_transcript_to_notion("Telegram Voice", f"User {user_id}", transcription, summary)
            except Exception as e:
                logger.error(f"Notion save error: {e}")

        # Send to n8n
        if N8N_WEBHOOK_URL:
            from modules.n8n_connector import send_transcript_to_n8n
            send_transcript_to_n8n("Telegram Voice", transcription, summary)

        os.unlink(ogg_path)
        os.unlink(wav_path)
        logger.info(f"Sent voice analysis to user {user_id}")

    except Exception as e:
        logger.error(f"Error processing voice: {e}")
        await update.message.reply_text("âŒ ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")


async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle images"""
    user_id = update.effective_user.id
    photo = update.message.photo[-1]

    logger.info(f"Received image from user {user_id}")

    if not model:
        await update.message.reply_text("âŒ Gemini AIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    try:
        file = await context.bot.get_file(photo.file_id)
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as img_file:
            await file.download_to_drive(img_file.name)
            img_path = img_file.name

        with open(img_path, 'rb') as image_file:
            image_data = image_file.read()

        res = generate_vision_safe(
            "ì´ë¯¸ì§€ë¥¼ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì œê³µí•˜ì„¸ìš”.",
            parts=[{"mime_type": "image/jpeg", "data": image_data}]
        )
        analysis = res.get("text") if res.get("ok") else "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤." 
        message = f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:\n\n{analysis}"
        await update.message.reply_text(message)

        # Save to Notion
        if NOTION_TOKEN:
            try:
                from modules.notion_updater import save_file_to_notion
                save_file_to_notion(f"Image_{user_id}.jpg", analysis, "Image")
            except Exception as e:
                logger.error(f"Notion save error: {e}")

        os.unlink(img_path)
        logger.info(f"Sent image analysis to user {user_id}")

    except Exception as e:
        logger.error(f"Error processing image: {e}")
        await update.message.reply_text("âŒ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle documents with improved processing"""
    user_id = update.effective_user.id
    document = update.message.document

    logger.info(f"Received document from user {user_id}: {document.file_name}")

    try:
        file = await context.bot.get_file(document.file_id)
        file_ext = os.path.splitext(document.file_name)[1].lower()
        temp_file = tempfile.NamedTemporaryFile(suffix=file_ext, delete=False)
        await file.download_to_drive(temp_file.name)
        temp_file.close()  # Close file handle explicitly
        doc_path = temp_file.name

        # Extract content depending on type
        if file_ext == '.pdf':
            text_content = extract_text_from_pdf(doc_path)
            mode = 'summary'
        elif file_ext == '.docx':
            text_content = extract_text_from_docx(doc_path)
            mode = 'summary'
        elif file_ext in SUPPORTED_TEXT_EXTS:
            text_content = extract_text_from_txt(doc_path)
            mode = 'preview'
        else:
            await update.message.reply_text("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤. (.pdf, .docx, .txt, .md, .json, .xml, .html, .css, .js, .py ë“± í…ìŠ¤íŠ¸ íŒŒì¼ ì§€ì›)")
            if os.path.exists(doc_path):
                os.unlink(doc_path)
            return

        # For text-like files, show a plain text preview; for others, summarize
        if mode == 'preview':
            preview_limit = int(os.getenv('DOC_PREVIEW_LIMIT', '3500'))
            content = (text_content or '')
            if not content:
                content = "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
            if len(content) > preview_limit:
                preview = content[:preview_limit]
                message = f"ğŸ“„ íŒŒì¼ ë‚´ìš© (ì•ë¶€ë¶„ {preview_limit}ì):\n\n{preview}\n\nâ€¦ (ì´í•˜ ìƒëµ)"
            else:
                message = f"ğŸ“„ íŒŒì¼ ë‚´ìš©:\n\n{content}"
            await update.message.reply_text(message)
        else:
            if text_content and "ì‹¤íŒ¨" not in text_content:
                await update.message.reply_text("ğŸ“„ ë¬¸ì„œê°€ ê¸¸ì–´ Map-Reduce ìš”ì•½ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤â€¦")
                summary = map_reduce_summarize(text_content)
            else:
                summary = text_content or "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
            message = f"ğŸ“„ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼:\n\nìš”ì•½:\n{summary}"
            await update.message.reply_text(message)

        # Save to Notion
        if NOTION_TOKEN:
            try:
                from modules.notion_updater import save_file_to_notion
                save_file_to_notion(document.file_name, summary, "Document")
            except Exception as e:
                logger.error(f"Notion save error: {e}")

        # Send to n8n
        if N8N_WEBHOOK_URL:
            from modules.n8n_connector import send_file_to_n8n
            send_file_to_n8n(document.file_name, summary)

        if os.path.exists(doc_path):
            os.unlink(doc_path)
        logger.info(f"Sent document analysis to user {user_id}")

    except Exception as e:
        logger.error(f"Error processing document: {e}")
        await update.message.reply_text("âŒ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")


# =============================================================================
# GOOGLE DRIVE WATCHER
# =============================================================================

def load_processed_files():
    """Load processed files list"""
    try:
        if os.path.exists(PROCESSED_FILES_DB):
            with open(PROCESSED_FILES_DB, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    except Exception as e:
        logger.error(f"Error loading processed files: {e}")
        return []


def save_processed_files(processed_list):
    """Save processed files list"""
    try:
        with open(PROCESSED_FILES_DB, 'w', encoding='utf-8') as f:
            json.dump(processed_list, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error saving processed files: {e}")


def initialize_drive_service():
    """Initialize Google Drive API service"""
    try:
        credentials = Credentials.from_service_account_file(
            GOOGLE_SERVICE_JSON_PATH,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        service = build('drive', 'v3', credentials=credentials)
        logger.info("âœ… Google Drive service initialized")
        return service
    except Exception as e:
        logger.error(f"âŒ Drive service error: {e}")
        return None


def get_new_files_from_drive(service, processed_files):
    """Get new files from Drive"""
    try:
        results = service.files().list(
            q=f"'{DRIVE_FOLDER_ID}' in parents and trashed=false",
            pageSize=100,
            fields="nextPageToken, files(id, name, mimeType)"
        ).execute()
        items = results.get('files', [])
        return [item for item in items if item['id'] not in processed_files]
    except Exception as e:
        logger.error(f"Error getting Drive files: {e}")
        return []


def download_file_from_drive(service, file_id, file_name):
    """Download file from Drive"""
    try:
        request = service.files().get_media(fileId=file_id)
        file_path = os.path.join(tempfile.gettempdir(), file_name)

        with open(file_path, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                _, done = downloader.next_chunk()

        return file_path
    except Exception as e:
        logger.error(f"Download error: {e}")
        return None


def analyze_drive_file(file_path, mime_type):
    """Analyze file from Drive with improved long text handling"""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()

        if mime_type == 'application/pdf' or file_ext == '.pdf':
            text = extract_text_from_pdf(file_path)
        elif mime_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' or file_ext == '.docx':
            text = extract_text_from_docx(file_path)
        elif mime_type == 'text/plain' or file_ext == '.txt':
            text = extract_text_from_txt(file_path)
        elif mime_type == 'text/markdown' or file_ext == '.md':
            text = extract_text_from_txt(file_path)
        elif mime_type.startswith('image/'):
            with open(file_path, 'rb') as f:
                data = f.read()
            res = generate_vision_safe(
                "ì´ë¯¸ì§€ë¥¼ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.",
                parts=[{"mime_type": mime_type, "data": data}]
            )
            return res.get("text") if res.get("ok") else "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤." 
        elif mime_type.startswith('audio/'):
            wav_path = file_path.replace(file_ext, '.wav')
            if convert_voice_to_wav(file_path, wav_path):
                transcription = transcribe_audio(wav_path)
                os.unlink(wav_path)
                if model:
                    res = generate_text_safe(f"ìŒì„± ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì œê³µí•˜ì„¸ìš”.\n\n{transcription}")
                    summary = res.get("text") if res.get("ok") else "ìŒì„± ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    return f"ì „ì‚¬:\n{transcription}\n\në¶„ì„:\n{summary}" 
                return transcription
            return "ìŒì„± ë³€í™˜ ì‹¤íŒ¨"
        else:
            return "ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤."

        if model and text and "ì‹¤íŒ¨" not in text:
            return map_reduce_summarize(text)
        return text

    except Exception as e:
        logger.error(f"Analysis error: {e}")
        return "íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"


async def send_telegram_message(bot, text):
    """Send message to Telegram"""
    try:
        if OWNER_ID:
            await bot.send_message(chat_id=OWNER_ID, text=text)
            logger.info(f"ğŸ“± Telegram message sent")
    except Exception as e:
        logger.error(f"Telegram send error: {e}")


def drive_watcher_thread(application):
    """Monitor Google Drive folder"""
    logger.info("ğŸ” Google Drive watcher started")

    service = initialize_drive_service()
    if not service:
        logger.error("âŒ Drive service failed. Exiting.")
        return

    processed_files = load_processed_files()

    while True:
        try:
            new_files = get_new_files_from_drive(service, processed_files)

            if new_files:
                logger.info(f"[Drive] Found {len(new_files)} new file(s)")

                for file_info in new_files:
                    file_id = file_info['id']
                    file_name = file_info['name']
                    mime_type = file_info['mimeType']

                    logger.info(f"[Drive] New file: {file_name}")

                    file_path = download_file_from_drive(service, file_id, file_name)
                    if not file_path:
                        continue

                    analysis = analyze_drive_file(file_path, mime_type)
                    formatted_file, mode_file = format_ai_text(file_name)
                    formatted_analysis, mode_ana = format_ai_text(analysis)
                    mode = mode_file if mode_file == mode_ana else 'HTML'
                    if mode == 'HTML':
                        message = (
                            f"ğŸ“‚ íŒŒì¼: {formatted_file}\n\n"
                            f"<b>ğŸ“ Gemini ë¶„ì„ ê²°ê³¼:</b>\n{formatted_analysis}"
                        )
                    else:
                        message = (
                            f"ğŸ“‚ íŒŒì¼: {formatted_file}\n\n"
                            f"*ğŸ“ Gemini ë¶„ì„ ê²°ê³¼:*\n{formatted_analysis}"
                        )

                    # Override to plain text message (no Markdown)
                    message = (
                        f"ğŸ“‚ íŒŒì¼: {file_name}\n\n"
                        f"ğŸ“ Gemini ë¶„ì„ ê²°ê³¼:\n{analysis}"
                    )

                    # Send to Telegram
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        loop.run_until_complete(application.bot.send_message(chat_id=OWNER_ID, text=message))
                    finally:
                        loop.close()

                    # Save to Notion
                    if NOTION_TOKEN:
                        try:
                            from modules.notion_updater import save_file_to_notion
                            save_file_to_notion(file_name, analysis, "Drive File")
                        except Exception as e:
                            logger.error(f"Notion error: {e}")

                    # Send to n8n
                    if N8N_WEBHOOK_URL:
                        from modules.n8n_connector import send_file_to_n8n
                        send_file_to_n8n(file_name, analysis)

                    os.unlink(file_path)
                    processed_files.append(file_id)
                    save_processed_files(processed_files)
                    logger.info(f"[Drive] Completed: {file_name}")

            time.sleep(60)

        except Exception as e:
            logger.error(f"Drive watcher error: {e}")
            time.sleep(60)


# =============================================================================
# ERROR HANDLER
# =============================================================================

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle errors"""
    logger.warning(f'Error: {context.error}')
    if update and update.effective_message:
        await update.effective_message.reply_text("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


# =============================================================================
# MAIN FUNCTION
# =============================================================================

def build_app() -> Application:
    """Build the Telegram application with enhanced handlers"""
    app: Application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    
    # Core handlers
    app.add_handler(CommandHandler("start", start))

    
    # Message handlers
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice_message))
    app.add_handler(MessageHandler(filters.PHOTO, handle_image))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    
    # Error handler
    app.add_error_handler(error_handler)
    
    return app


def main():
    """
    Start all automation modules with enhanced configuration
    """
    logger.info("=" * 60)

    # === [AUTO-INJECT] boot ===
    setup_logger("app")
    assert_env()
    # === [/AUTO-INJECT] ===

    logger.info("ğŸ¤– AI ìë™í™” í—ˆë¸Œ ì‹œì‘ (ê°œì„ ëœ ë²„ì „)")
    logger.info("=" * 60)

    # Create Telegram application
    application = build_app()

    # === [AUTO-INJECT] register commands ===
    # Commands are registered in build_app()


    # === [AUTO-INJECT] drive schedule ===
    import os, threading, time

    def _fetch_list():
        # TODO: Google Drive API ì—°ë™ í•¨ìˆ˜ë¡œ êµì²´ (list: [{id,name,mimeType}, ...])
        return []

    def _handle_file(f):
        # TODO: íŒŒì¼ ë‹¤ìš´ë¡œë“œ â†’ ìš”ì•½ â†’ ì•Œë¦¼/ì €ì¥ ë¡œì§
        pass

    def _drive_loop():
        while True:
            try:
                if poll_drive_once:
                    poll_drive_once(_fetch_list, _handle_file)
            except Exception as e:
                logger.exception(f"[drive] {e}")
            time.sleep(60)

    if os.getenv("DRIVE_FOLDER_ID") and poll_drive_once and "AUTO_DRIVE_LOOP" not in globals():
        AUTO_DRIVE_LOOP = True
        threading.Thread(target=_drive_loop, daemon=True).start()
        logger.info("Drive watcher thread started.")
    # === [/AUTO-INJECT] ===


    # Start Google Drive watcher
    if DRIVE_FOLDER_ID:
        drive_thread = threading.Thread(target=drive_watcher_thread, args=(application,), daemon=True)
        drive_thread.start()
        logger.info("âœ… Google Drive watcher started")
    else:
        logger.info("âš ï¸ Drive monitoring disabled")

    # Start Gmail watcher
    if os.getenv("GMAIL_CLIENT_SECRET_PATH"):
        try:
            import asyncio
            from modules.gmail_watcher import gmail_watcher_thread
            from modules.gemini_client import get_gemini_client

            gmail_thread = threading.Thread(
                target=gmail_watcher_thread,
                args=(get_gemini_client(), application.bot),
                daemon=True
            )
            gmail_thread.start()
            logger.info("âœ… Gmail watcher started")
        except Exception as e:
            logger.error(f"âŒ Gmail watcher failed: {e}")
    else:
        logger.info("âš ï¸ Gmail monitoring disabled")

    # Start Calendar checker
    if os.getenv("GMAIL_CLIENT_SECRET_PATH"):
        try:
            from modules.calendar_checker import calendar_checker_thread
            from modules.gemini_client import get_gemini_client

            calendar_thread = threading.Thread(
                target=calendar_checker_thread,
                args=(get_gemini_client(), application.bot),
                daemon=True
            )
            calendar_thread.start()
            logger.info("âœ… Calendar checker started")
        except Exception as e:
            logger.error(f"âŒ Calendar checker failed: {e}")
    else:
        logger.info("âš ï¸ Calendar monitoring disabled")

    # Start Slack watcher
    if SLACK_BOT_TOKEN:
        try:
            from modules.slack_handler import slack_watcher_thread
            from modules.gemini_client import get_gemini_client

            slack_thread = threading.Thread(
                target=slack_watcher_thread,
                args=(get_gemini_client(), application.bot),
                daemon=True
            )
            slack_thread.start()
            logger.info("âœ… Slack watcher started")
        except Exception as e:
            logger.error(f"âŒ Slack watcher failed: {e}")
    else:
        logger.info("âš ï¸ Slack integration disabled")

    # Start polling
    logger.info("âœ… ëª¨ë“  ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    logger.info("ğŸ“¡ Telegram ë´‡ í´ë§ ì‹œì‘...")
    logger.info("=" * 60)
    application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)


if __name__ == '__main__':
    main()
